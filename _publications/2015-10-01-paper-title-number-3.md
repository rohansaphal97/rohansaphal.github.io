---
title: "SEERL: Sample Efficient Ensemble Reinforcement Learning"
collection: publications
permalink: /publication/2015-10-01-paper-title-number-3
excerpt: 'Ensemble learning is a very prevalent method employed in machine learning. The
relative success of ensemble methods is attributed to its ability to tackle a wide range
of instances and complex problems that require different low-level approaches.
However, ensemble methods are relatively less popular in reinforcement learning
owing to the high sample complexity and computational expense involved. We
present a new training and evaluation framework for model-free algorithms that use
ensembles of policies obtained from a single training instance. These policies are
diverse in nature and are learned through directed perturbation of the model parameters at regular intervals. We show that learning an adequately diverse set of policies
is required for a good ensemble while extreme diversity can prove detrimental to
overall performance. We evaluate our approach to challenging discrete and continuous control tasks and also discuss various ensembling strategies. Our framework
is substantially sample efficient, computationally inexpensive and is seen to outperform state of the art(SOTA) scores in Atari 2600 and Mujoco. Video results can be
found [here](https://www.youtube.com/channel/UC95Kctu9Mp8BlFmtGD2TGTA)'
date: 2020-10-01
venue: 'the Proceedings of the Thirty-Fourth
AAAI Conference on Artificial Intelligence (AAAI-20). AAAI Press'
paperurl: ''
citation: 'Rohan Saphal, Balaraman Ravindran, Dheevatsa Mudigere, Sasikant Avancha, and Bharat Kaul. "SEERL:
Sample Efficient Ensemble Reinforcement Learning." To appear in the Proceedings of the Thirty-Fourth
AAAI Conference on Artificial Intelligence (AAAI-20). AAAI Press'
---
Ensemble learning is a very prevalent method employed in machine learning. The
relative success of ensemble methods is attributed to its ability to tackle a wide range
of instances and complex problems that require different low-level approaches.
However, ensemble methods are relatively less popular in reinforcement learning
owing to the high sample complexity and computational expense involved. We
present a new training and evaluation framework for model-free algorithms that use
ensembles of policies obtained from a single training instance. These policies are
diverse in nature and are learned through directed perturbation of the model parameters at regular intervals. We show that learning an adequately diverse set of policies
is required for a good ensemble while extreme diversity can prove detrimental to
overall performance. We evaluate our approach to challenging discrete and continuous control tasks and also discuss various ensembling strategies. Our framework
is substantially sample efficient, computationally inexpensive and is seen to outperform state of the art(SOTA) scores in Atari 2600 and Mujoco. Video results can be
found [here](https://www.youtube.com/channel/UC95Kctu9Mp8BlFmtGD2TGTA)

[Download paper here](http://rohansaphal97.github.io/files/SEERL_arxiv.pdf)

Recommended citation: 'Rohan Saphal, Balaraman Ravindran, Dheevatsa Mudigere, Sasikant Avancha, and Bharat Kaul. "SEERL:
Sample Efficient Ensemble Reinforcement Learning." To appear in the Proceedings of the Thirty-Fourth
AAAI Conference on Artificial Intelligence (AAAI-20). AAAI Press'
